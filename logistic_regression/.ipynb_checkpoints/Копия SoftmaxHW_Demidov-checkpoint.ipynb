{"cells":[{"cell_type":"markdown","id":"5491bdaf-7145-444d-b7e8-ae4569e0124d","metadata":{"id":"5491bdaf-7145-444d-b7e8-ae4569e0124d"},"source":["# Домашнее задание №1. Softmax Regression."]},{"cell_type":"markdown","id":"6226b035-0166-4361-a967-28a2d2b58f96","metadata":{"id":"6226b035-0166-4361-a967-28a2d2b58f96"},"source":["Нужно реализовать много-классовую логистическую регрессию с помощью softmax c поддержкой L1/L2 регуляризации. После этого сравнить с sklearn реализацией [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n"," с настройкой **multinomial**."]},{"cell_type":"markdown","id":"aecb3719-580c-4641-b58b-8b088bc77954","metadata":{"id":"aecb3719-580c-4641-b58b-8b088bc77954"},"source":["## Задание №1 (10 баллов)\n","\n","Реализовать класс SoftMaxRegression и его методы - init, fit, predict c возможностью конфигурации\n","регуляризации. \n","Для оптимизации функции ошибки воспользоваться методом **стохастического градиентного спуска**. \n","\n","Остальные функции реализовать на ваше усмотрение. "]},{"cell_type":"code","execution_count":1,"id":"64d60fcc-452f-40cb-9eb0-a9941d0d6a80","metadata":{"id":"64d60fcc-452f-40cb-9eb0-a9941d0d6a80","executionInfo":{"status":"ok","timestamp":1670832832469,"user_tz":-180,"elapsed":6,"user":{"displayName":"Станислав Демидов","userId":"00398676290972506703"}}},"outputs":[],"source":["class SoftMaxRegression:\n","    def __init__(self, n_epochs=200, lr=0.9, regularization_type=None):\n","        self.n_epochs = n_epochs\n","        self.lr = lr\n","        self.regularization_type = regularization_type\n","        \n","    def softmax(self, x):\n","        e_x = np.exp(x - np.max(x, axis=1, keepdims=True)) \n","        return e_x / np.sum(e_x, axis=1, keepdims=True)\n","\n","    def onehot(self, X):\n","        n_samples = np.shape(X)[0]\n","        categories = np.unique(X)\n","        mapping = {}\n","        for id, category in enumerate(categories):\n","            mapping[category] = id\n","        ohe_array = np.zeros((n_samples, len(categories)))\n","        for row_number, instance in enumerate(X):\n","            ohe_array[row_number, mapping[instance]] = 1\n","        return ohe_array\n","\n","    def fit(self, X, y):\n","        \"\"\"функция обучения модели\"\"\"\n","        # CODE HERE\n","        X = np.insert(X, 0, 1, axis=1)\n","        n_features = X.shape[1]\n","        n_classes = len(np.unique(y))\n","\n","        self.weights = np.random.random((n_features, n_classes))\n","\n","        if self.regularization_type == 'l1':\n","            grad_penalty = 0.5 * np.sign(self.weights)\n","        elif self.regularization_type == 'l2':\n","            grad_penalty = np.asarray(0.5) * self.weights\n","        else:\n","            grad_penalty = 0\n","\n","        beta = 0.9\n","        step = 0.2\n","        \n","        for epoch in range(self.n_epochs):\n","            \n","            loss_list = []\n","            acc_list = []\n","            m = len(X)\n","            batch_size = 30000\n","            n_batch = ceil(m / batch_size)   \n","            \n","            for j in range(n_batch):\n","                X_batch = X[j * batch_size:min((j + 1) * batch_size, m)]\n","                y_batch = y[j * batch_size:min((j + 1) * batch_size, m)]             \n","                y_preds = self.softmax(X_batch.dot(self.weights))\n","                grad = X_batch.T.dot(y_preds - self.onehot(y_batch)) + grad_penalty\n","                step = beta*step + self.lr * grad\n","                self.weights -= step\n","        \n","            #loss = (1/X_batch.shape[0])*np.sum(-np.log(self.softmax(X_batch.dot(self.coef_))[range(y_batch.shape[0]), y_batch]))\n","            #print(\"Epoch: {} , Loss: {}\".format(epoch, loss))\n","            #current_acc = accuracy_score()\n","        return self\n","    \n","    def predict(self, X):\n","        \"\"\"функция предсказания\"\"\"\n","        # CODE HERE\n","        X = np.insert(X, 0, 1, axis=1)\n","        probas = self.softmax(X.dot(self.weights))\n","        return np.argmax(probas, axis=1)"]},{"cell_type":"code","source":["def accuracy_score(y_pred, y_true):\n","        accuracy = np.mean(y_pred == y_true)\n","        return accuracy"],"metadata":{"id":"ha5evITzRu4f","executionInfo":{"status":"ok","timestamp":1670832834440,"user_tz":-180,"elapsed":7,"user":{"displayName":"Станислав Демидов","userId":"00398676290972506703"}}},"id":"ha5evITzRu4f","execution_count":2,"outputs":[]},{"cell_type":"code","source":["class StandardScaler:\n"," \n","    def fit(self, X):\n","        self.mean = np.mean(X, axis=0)\n","        self.var = np.var(X, axis=0)\n","\n","    def transform(self, X):\n","        X_scal = (X - self.mean) / np.sqrt(self.var)\n","        return X_scal\n","\n","    def fit_transform(self, X):\n","        self.fit(X)\n","        return self.transform(X)"],"metadata":{"id":"0EGy3OPtRj-F","executionInfo":{"status":"ok","timestamp":1670832834441,"user_tz":-180,"elapsed":5,"user":{"displayName":"Станислав Демидов","userId":"00398676290972506703"}}},"id":"0EGy3OPtRj-F","execution_count":3,"outputs":[]},{"cell_type":"markdown","id":"4114753f-27f8-4042-a4cb-538573346bc0","metadata":{"id":"4114753f-27f8-4042-a4cb-538573346bc0"},"source":["## Задание №2 (10 баллов)"]},{"cell_type":"markdown","id":"266f6022-67ee-43fc-b78b-5b066d0e6a64","metadata":{"id":"266f6022-67ee-43fc-b78b-5b066d0e6a64"},"source":["Загрузите любой датасет много-классовой классификации, сделайте предобработку, разбейте на тренировочную и тестовую выборку  и оцените работу вашего алгоритма. Предпочтительно использовать метрику точности(accuracy) для оценки алгоритма. \n","\n","В рамках оценки, воспользуйтесь sklearn реализацией много-классовой логистической регрессии. **Проверьте что ваши метрики совпадают(+/-1-2%) на моделях без регуляризации, с L1 и с L2 регуляризации.**"]},{"cell_type":"markdown","id":"f744d49d-24ae-4f73-af67-49b0677fd466","metadata":{"id":"f744d49d-24ae-4f73-af67-49b0677fd466"},"source":["#### Работа с датасетом (1 балл)\n","\n","Загрузите выбранный датасет много-классовой классификации, обработайте его, сделайте разбиение на тренировочную и тестовую выборку. Датасеты для классификации можно взять например [**отсюда**](https://archive.ics.uci.edu/ml/datasets.php?format=&task=cla&att=&area=&numAtt=&numIns=&type=&sort=nameUp&view=table)."]},{"cell_type":"code","execution_count":10,"id":"bba8504e-3f39-4168-b9cc-709ac87f1ad7","metadata":{"id":"bba8504e-3f39-4168-b9cc-709ac87f1ad7","executionInfo":{"status":"ok","timestamp":1670833962032,"user_tz":-180,"elapsed":681,"user":{"displayName":"Станислав Демидов","userId":"00398676290972506703"}}},"outputs":[],"source":["### CODE HERE\n","import numpy as np\n","from keras.datasets import mnist\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from math import *\n","\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train = X_train.reshape(60000, 28*28)\n","X_test = X_test.reshape(10000, 28*28)"]},{"cell_type":"markdown","id":"874392d6-7944-4244-a14b-b8d5bdbf0d66","metadata":{"id":"874392d6-7944-4244-a14b-b8d5bdbf0d66"},"source":["#### Обучение модели и сравнение с sklearn имплементацией"]},{"cell_type":"markdown","id":"4dcc65a7-ab03-4129-bba2-acde566b31ee","metadata":{"id":"4dcc65a7-ab03-4129-bba2-acde566b31ee"},"source":["Обучите 3 модели - обычную, с L1 реализацией, с L2 реализацией и сравните с аналогичными sklearn имплементациями много-классовой логистической регрессии. "]},{"cell_type":"markdown","id":"1b0152dc-da7e-42a1-bf62-5095e370ed54","metadata":{"id":"1b0152dc-da7e-42a1-bf62-5095e370ed54"},"source":["В рамках обучения модели требуется визуализировать:\n","\n","1) График падания значений ошибки на тренировочной выборке в зависимости от итерации.\n","2) График падания значений ошибки на валидационной выборке в зависимости от итерации.\n","3) График роста метрики точности в зависимости от итерации.\n","\n","<span style=\"color:red\">**Модель считается успешно реализованной, если целевая метрика совпадает с sklearn реализацией. Если разница большая(более 2%), баллы за ДЗ не проставляются.**</span>\n"]},{"cell_type":"markdown","id":"70265566-d186-495f-aa78-022769d8f05d","metadata":{"id":"70265566-d186-495f-aa78-022769d8f05d"},"source":["#### Обучение обычной модели и сравнение с __LogisticRegression(penalty = 'none', multi_class='multinomial')__ (3 балла)"]},{"cell_type":"code","execution_count":5,"id":"6cc24404-2c16-48ec-ae2c-7752f64c3ac4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cc24404-2c16-48ec-ae2c-7752f64c3ac4","executionInfo":{"status":"ok","timestamp":1670832949084,"user_tz":-180,"elapsed":105944,"user":{"displayName":"Станислав Демидов","userId":"00398676290972506703"}},"outputId":"ac31630e-ceab-4e51-9cd5-02613cdd0306"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-3-610eed7bdb59>:8: RuntimeWarning: invalid value encountered in true_divide\n","  X_scal = (X - self.mean) / np.sqrt(self.var)\n","<ipython-input-3-610eed7bdb59>:8: RuntimeWarning: divide by zero encountered in true_divide\n","  X_scal = (X - self.mean) / np.sqrt(self.var)\n"]},{"output_type":"stream","name":"stdout","text":["my score: 0.9128,\n","sklearn score: 0.9243\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["### CODE HERE\n","scaler = StandardScaler()\n","scaler.fit_transform(X_train)\n","scaler.transform(X_test)\n","\n","clf_0 = SoftMaxRegression(n_epochs=100, lr=0.9, regularization_type=None)\n","clf_0.fit(X_train, y_train)\n","y_preds = clf_0.predict(X_test)\n","\n","my_score = accuracy_score(y_test, y_preds)\n","\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","sklearn_logreg = LogisticRegression(penalty='none', multi_class='multinomial')\n","sklearn_logreg.fit(X_train, y_train)\n","#accuracy_score(sklearn_logreg.predict(X_test), y_test)\n","\n","\n","print(\"my score: {},\\nsklearn score: {}\".format(my_score, accuracy_score(sklearn_logreg.predict(X_test), y_test)))"]},{"cell_type":"markdown","id":"c7ad098a-096b-4120-8cf2-19ddbb21bb63","metadata":{"id":"c7ad098a-096b-4120-8cf2-19ddbb21bb63"},"source":["#### Обучение модели c L1 регуляризацией и сравнение с __LogisticRegression(penalty = 'l1', multi_class='multinomial')__ (3 балла)"]},{"cell_type":"code","execution_count":11,"id":"98ff36e1-c0f2-49e7-b839-e7b843cec83a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98ff36e1-c0f2-49e7-b839-e7b843cec83a","executionInfo":{"status":"ok","timestamp":1670834021606,"user_tz":-180,"elapsed":52373,"user":{"displayName":"Станислав Демидов","userId":"00398676290972506703"}},"outputId":"4d834aad-7d5f-41ea-d152-ca649ffbf7ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["my score 0.9084\n"]}],"source":["### CODE HERE\n","clf_1 = SoftMaxRegression(n_epochs=100, lr=0.9, regularization_type='l1')\n","clf_1.fit(X_train, y_train)\n","y_preds = clf_1.predict(X_test)\n","\n","my_score = accuracy_score(y_test, y_preds)\n","print(f\"my score {my_score}\")\n","\n","# from sklearn.linear_model import LogisticRegression\n","\n","# sklearn_logreg = LogisticRegression(penalty='l1', multi_class='multinomial')\n","# sklearn_logreg.fit(X_train, y_train)\n","# #accuracy_score(sklearn_logreg.predict(X_test), y_test)\n","\n","\n","# print(\"my score: {} ,\\nsklearn score: {}\".format(my_score, accuracy_score(sklearn_logreg.predict(X_test), y_test)))"]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","sklearn_logreg = LogisticRegression(penalty='l1', multi_class='multinomial', solver='saga')\n","sklearn_logreg.fit(X_train, y_train)\n","#accuracy_score(sklearn_logreg.predict(X_test), y_test)\n","\n","\n","print(\"my score: {} ,\\nsklearn score: {}\".format(my_score, accuracy_score(sklearn_logreg.predict(X_test), y_test)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6XRCYRa_V2Cf","executionInfo":{"status":"ok","timestamp":1670833782978,"user_tz":-180,"elapsed":731567,"user":{"displayName":"Станислав Демидов","userId":"00398676290972506703"}},"outputId":"95f093b3-3437-4227-cca1-9d01335444ff"},"id":"6XRCYRa_V2Cf","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["my score: 0.9115 ,\n","sklearn score: 0.9257\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","id":"c03acd91-cf5c-4873-8450-4ac873a2dea0","metadata":{"id":"c03acd91-cf5c-4873-8450-4ac873a2dea0"},"source":["#### Обучение модели c L2 регуляризацией и сравнение с __LogisticRegression(penalty = 'l2', multi_class='multinomial')__ (3 балла)"]},{"cell_type":"code","execution_count":9,"id":"bb7ca2af-c05b-4106-bedc-557690ad8eee","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bb7ca2af-c05b-4106-bedc-557690ad8eee","executionInfo":{"status":"ok","timestamp":1670833893483,"user_tz":-180,"elapsed":98535,"user":{"displayName":"Станислав Демидов","userId":"00398676290972506703"}},"outputId":"5fb82942-f7f2-4952-ade1-44bbab9c4cf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["my score: 0.9131,\n","sklearn score: 0.9255\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["### CODE HERE\n","clf_2 = SoftMaxRegression(n_epochs=100, lr=0.9, regularization_type='l2')\n","clf_2.fit(X_train, y_train)\n","y_preds = clf_2.predict(X_test)\n","\n","my_score = accuracy_score(y_test, y_preds)\n","\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","sklearn_logreg = LogisticRegression(penalty='l2', multi_class='multinomial')\n","sklearn_logreg.fit(X_train, y_train)\n","#accuracy_score(sklearn_logreg.predict(X_test), y_test)\n","\n","\n","print(\"my score: {},\\nsklearn score: {}\".format(my_score, accuracy_score(sklearn_logreg.predict(X_test), y_test)))"]},{"cell_type":"code","source":[],"metadata":{"id":"c9-iRueDdGvt"},"id":"c9-iRueDdGvt","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}